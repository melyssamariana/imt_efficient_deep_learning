HYPERPARAMETERS BEFORE CHANGES
================================
Date: 5 f√©vrier 2026

Training Configuration:
- Number of epochs: 80
- Learning rate: 0.1
- Batch size: 32
- Optimizer: SGD
  - Momentum: 0.9
  - Weight decay: 5e-4

Learning Rate Scheduler:
- Type: CosineAnnealingLR
- T_max: 80

Model:
- Architecture: ResNet18

Dataset:
- Training samples: 15,000 (subset)
- Test samples: 10,000
- Data augmentation: RandomCrop(32, padding=4), RandomHorizontalFlip

Loss Function:
- CrossEntropyLoss

Device:
- GPU (if available) / CPU

Best Accuracy Achieved: 89%
